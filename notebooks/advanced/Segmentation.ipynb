{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, functools, itertools, collections, time, random, pickle, warnings, json, subprocess\n",
    "pkg_path = '/home/jupyter/code'\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas\n",
    "from skimage.color import label2rgb\n",
    "from skimage.measure import regionprops, label\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utility import get_label_image, get_cor, get_cor_map, get_topk_indices, get_cor_map_4d, get_local_mean\n",
    "from utility import get_prime_factors, get_local_median, scale_and_shift, adaptive_avg_pool\n",
    "from utility import mark_points_in_intervals, cosine_similarity\n",
    "from visualization import imshow, plot_image_label_overlay, make_video_ffmpeg, get_good_colors, plot_colortable, save_gif_file\n",
    "from models import UNet\n",
    "from denoise import get_denoised_mat, model_denoise, SeparateNet\n",
    "from segmentation import semi_supervised_segmentation, split_clusters\n",
    "from optical_electrophysiology import extract_traces\n",
    "from optical_electrophysiology import load_file\n",
    "from optical_electrophysiology import detrend_linear, basic_segmentation, entire_pipeline\n",
    "\n",
    "use_gpu = True\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "good_colors = get_good_colors()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'gs://broad-opp-voltage/2020-07-23_VoltageMovies_SCDN011'\n",
    "entire_pipeline(bucket, result_folder='results1', bin_files='153316_1992_NR_d4inf_freezethaw_D32_FOV1', delete_local_data=True, \n",
    "                denoise=True, denoise_model_config=None, denoise_loss_threshold=0, denoise_num_epochs=2, denoise_num_iters=600, \n",
    "                apply_spectral_clustering=True, spectral_soft_threshold=True, spectral_cor_threshold=None,\n",
    "                display=True, verbose=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'gs://broad-opp-voltage/2020-07-16_VoltageMovies_SCDN010'\n",
    "bucket = 'gs://broad-opp-voltage/2020-07-23_VoltageMovies_SCDN011'\n",
    "# bucket = 'gs://broad-opp-voltage/2020-07-30_VoltageMovies_MIN002'\n",
    "command = ['gsutil', 'ls', bucket]\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0\n",
    "\n",
    "filepaths = response.stdout.decode().split()\n",
    "bin_files = sorted([f.split('.')[0].split('/')[-1] for f in filepaths if re.search('.bin$', f)])\n",
    "\n",
    "data_folder = bucket.split('/')[-1]\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "if not os.path.exists(f'{data_folder}/results'):\n",
    "    print(f'Create folder {data_folder}/results')\n",
    "    os.makedirs(f'{data_folder}/results')\n",
    "if not os.path.exists(f'{data_folder}/json'):\n",
    "    print(f'Create folder {data_folder}/json')\n",
    "    os.makedirs(f'{data_folder}/json')\n",
    "    command = ['gsutil', '-m', 'cp', f'{bucket}/*.json', f'{data_folder}/json']\n",
    "    response = subprocess.run(command, capture_output=True)\n",
    "    assert response.returncode == 0\n",
    "\n",
    "meta_data = {}\n",
    "for file in bin_files:\n",
    "    meta_file = f'{data_folder}/json/{file}_metadata.json'\n",
    "    if not os.path.exists(meta_file):\n",
    "        command = ['gsutil', 'cp', f'{bucket}/{file}_metadata.json', meta_file]\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        if response.returncode != 0:\n",
    "            print(f'{meta_file} does not exist!')\n",
    "            continue\n",
    "    try:\n",
    "        with open(meta_file, 'r') as f:\n",
    "                meta_data[file] = json.load(f)\n",
    "    except ValueError:\n",
    "        with open(meta_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip() for line in lines]\n",
    "            lines = [re.sub('Null', 'null', line) for line in lines if line!=',']\n",
    "            lines = functools.reduce(lambda x, y: x+y, lines)\n",
    "            meta_data[file] = json.loads(lines)\n",
    "    if 'blueFrameOnOff' not in meta_data[file]:\n",
    "        meta_data[file]['blueFrameOnOff'] = functools.reduce(lambda x, y: x+y, [[251+i*1000, 750+i*1000] for i in range(2, 10)])      \n",
    "        with open(meta_file, 'w') as f:\n",
    "            json.dump(meta_data[file], f, indent=2)\n",
    "bin_files = [k for k in bin_files if k in meta_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for file in bin_files[:1]:\n",
    "    print(f'Process {file}')\n",
    "    if not os.path.exists(f'{data_folder}/{file}.bin'):\n",
    "        command = ['gsutil', '-m', 'cp', f'{bucket}/{file}.bin', data_folder]\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "    save_folder = f'{data_folder}/results/{file}'\n",
    "    if not os.path.exists(save_folder):\n",
    "        print(f'Create folder {save_folder}')\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    nframe = meta_data[file]['numFramesRequested']\n",
    "    ncol, nrow = meta_data[file]['movSize']\n",
    "    torch.cuda.empty_cache()\n",
    "    mat = load_file(f'{data_folder}/{file}.bin', size=(nframe, nrow, ncol))\n",
    "    blue_light_on_off = np.array(meta_data[file]['blueFrameOnOff']).reshape(-1, 2)\n",
    "    cor_map, label_image, regions = basic_segmentation(\n",
    "        torch.stack([mat[i-1:j-1] for i, j in blue_light_on_off], dim=0), min_pixels=20,\n",
    "        show=False, median_detrend=False, fft=False, fft_max_freq=200)\n",
    "    submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, median_detrend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    display = True\n",
    "    imshow(cor_map, save_file=f'{save_folder}/cor_map.png', title=f'{file}: min_cor={cor_map.min():.2f}, max_cor={cor_map.max():.2f}', \n",
    "           display=display)\n",
    "    plot_image_label_overlay(cor_map, label_image=label_image, regions=regions, save_file=f'{save_folder}/basic_segmentation.png', \n",
    "                             title=f'{file}: {label_image.max()} neurons detected', \n",
    "                             display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_mat = mat.new_tensor(np.load('tmp/denoised_mat.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=None, median_detrend=False)\n",
    "    submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=None, median_detrend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_multiple_traces\n",
    "plot_multiple_traces(traces, colors=good_colors, multiple_figures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "for i in range(len(traces)):\n",
    "    ax.plot(traces[i].cpu(), '-', label=i+1, c=good_colors[i], alpha=0.5)\n",
    "    ax.plot(denoised_traces[i].cpu(), '-', label=i+1, c=good_colors[i])\n",
    "    ax.text(-len(traces[i])*0.02, traces[i, :10].mean().cpu(), i+1, c=good_colors[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optical_electrophysiology import denoise_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it in a function in visualization\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "for i in range(len(traces)):\n",
    "    ax.plot(traces[i].cpu(), label=i+1, c=good_colors[i%len(good_colors)], alpha=0.5)\n",
    "    ax.plot(denoise_trace(traces[i]).cpu(), label=i+1, c=good_colors[i%len(good_colors)])\n",
    "    ax.text(-len(traces[i])*0.02, traces[i, :10].mean().cpu(), i+1, c=good_colors[i%len(good_colors)])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pop('b', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_model = None\n",
    "denoise_model_config = {}\n",
    "loss_history = []\n",
    "verbose = True\n",
    "features = True\n",
    "loss_threshold = 0\n",
    "save_folder = 'tmp'\n",
    "\n",
    "denoised_mat, denoise_model = get_denoised_mat(mat, features=features, model=denoise_model, save_folder=save_folder, \n",
    "                                               loss_threshold=loss_threshold, loss_history=loss_history, verbose=verbose, \n",
    "                                               optimizer_fn_args={'lr': 1e-3, 'weight_decay': 1e-2}, lr_scheduler=None, \n",
    "                                               out_channels=[64, 64, 128], kernel_size_unet=3, ndim=2, frame_depth=4,\n",
    "                                               last_out_channels=100, normalize=True, \n",
    "                                               num_epochs=12, num_iters=600, print_every=300, \n",
    "                                               batch_size=2, batch_size_eval=4, mask_prob=0.05, frame_weight=None, \n",
    "                                               save_intermediate_results=False, movie_start_idx=250, movie_end_idx=750, fps=60,\n",
    "                                               loss_reg_fn=nn.MSELoss(), optimizer_fn=torch.optim.AdamW, \n",
    "                                               window_size_row=None, window_size_col=None, weight=None, return_model=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(traces)):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    ax.plot(denoised_traces[i].cpu(), label=f'{i+1} raw', c=good_colors[i], alpha=0.5)\n",
    "    ax.plot(denoise_trace(traces[i]).cpu(), label=f'{i+1} denoised', c=good_colors[(i+len(traces))%len(good_colors)], alpha=0.5)\n",
    "    ax.text(-len(traces[i])*0.02, traces[i, :10].mean().cpu(), i+1, c=good_colors[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    np.save(f'{save_folder}/cor_map.npy', cor_map.cpu().numpy())\n",
    "    if len(traces) > 0:\n",
    "        print(f'{len(traces)} neuron detected in {file}.bin')\n",
    "        np.save(f'{save_folder}/label_image__basic_segmentation.npy', label_image.cpu().numpy())\n",
    "        np.save(f'{save_folder}/traces__basic_segmentation.npy', traces.cpu().numpy())\n",
    "    os.remove(f'{data_folder}/{file}.bin')\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n",
    "\n",
    "figsize = (20, 20)\n",
    "bounding_box = True\n",
    "for file in bin_files:\n",
    "    save_folder = f'{data_folder}/results/{file}'\n",
    "    if os.path.exists(f'{save_folder}/label_image__basic_segmentation.npy'):\n",
    "        cor_map = np.load(f'{save_folder}/cor_map.npy')\n",
    "        label_image = np.load(f'{save_folder}/label_image__basic_segmentation.npy')\n",
    "        traces = np.load(f'{save_folder}/traces__basic_segmentation.npy')\n",
    "        image_label_overlay = label2rgb(label_image, image=cor_map)\n",
    "        regions = regionprops(label_image)\n",
    "        if not os.path.exists(f'{save_folder}/figs'):\n",
    "            os.makedirs(f'{save_folder}/figs')\n",
    "        for sel_idx in range(label_image.max()):\n",
    "            fig, ax = plt.subplots(2, figsize=figsize)\n",
    "            ax[0].imshow(image_label_overlay)\n",
    "            if bounding_box:\n",
    "                region = regions[sel_idx]\n",
    "                minr, minc, maxr, maxc = region.bbox\n",
    "                rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                          fill=False, edgecolor='red', linewidth=2)\n",
    "                ax[0].add_patch(rect)\n",
    "                ax[0].text(minc-3, minr-1, sel_idx+1, color='r')\n",
    "            ax[0].set_axis_off()\n",
    "            ax[0].set_title(f'Neuron {sel_idx+1} segmentation')\n",
    "            ax[1].plot(traces[sel_idx])\n",
    "            ax[1].set_title(f'Neuron {sel_idx+1} trace')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{save_folder}/figs/{sel_idx+1}.png')\n",
    "            plt.close()\n",
    "        imgs = [f'{save_folder}/figs/{i+1}.png' for i in range(label_image.max())]\n",
    "        save_gif_file(imgs, save_path=f'{save_folder}/figs/{label_image.max()}_neurons.gif')\n",
    "\n",
    "command = ['gsutil', '-m', 'cp', '-r', \n",
    "           f'{data_folder}/results', \n",
    "           f'{bucket}/results2']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'optosynth_test_mb'\n",
    "# data_folder = '../data'\n",
    "\n",
    "mat = torch.from_numpy(np.load(f'{data_folder}/mat.npy')).float().to(device)\n",
    "masks = torch.from_numpy(np.load(f'{data_folder}/masks_nyx.npy')).to(device)\n",
    "soma_coords = torch.from_numpy(np.load(f'{data_folder}/soma_coords_n2.npy')).to(device)\n",
    "true_traces = torch.from_numpy(np.load(f'{data_folder}/neuron_mean_fluorescence_nt.npy')).float().to(device)\n",
    "nframe, nrow, ncol = mat.shape\n",
    "\n",
    "# trend = torch.from_numpy(np.load(f'{data_folder}/trend.npy')).float().to(device)\n",
    "# clean = torch.from_numpy(np.load(f'{data_folder}/clean.npy')).float().to(device)\n",
    "# target = clean - trend\n",
    "# mask_soma = torch.zeros(nrow, ncol).bool()\n",
    "# mask_soma[soma_coords[:, 1], soma_coords[:, 0]] = True\n",
    "# mask_cell = masks.float().max(0)[0].bool()\n",
    "# del clean, trend\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "save_folder = '2d-noise2self_with_features'\n",
    "filepath = f'{save_folder}/denoised_movie_full_step64000.npy'\n",
    "denoised_mat = torch.from_numpy(np.load(filepath)).float().to(device)\n",
    "# median = get_local_median(denoised_mat, dim=0)\n",
    "# denoised_mat = denoised_mat - median\n",
    "# mat_fft = torch.rfft(denoised_mat.transpose(0, 2), signal_ndim=1).reshape(ncol, nrow, -1).transpose(0, 2)\n",
    "\n",
    "median_detrend = False\n",
    "if median_detrend:\n",
    "    true_traces_median = get_local_median(true_traces, dim=-1)\n",
    "    true_traces -= true_traces_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = 'optosynth_test_mb'\n",
    "# mat = np.load(f'{data_folder}/mat.npy')\n",
    "# masks = np.load(f'{data_folder}/masks_nyx.npy')\n",
    "# true_traces = np.load(f'{data_folder}/neuron_mean_fluorescence_nt.npy')\n",
    "\n",
    "# os.makedirs('funimg_data')\n",
    "# np.save('funimg_data/mat.npy', np.ascontiguousarray(mat.transpose((1,2,0))))\n",
    "# np.save('funimg_data/neuron_masks_nyx.npy', masks)\n",
    "# np.save('funimg_data/neuron_traces_nt.npy', true_traces)\n",
    "\n",
    "# mat_detrended = mat - get_local_median(mat, window_size=50, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = 1\n",
    "nframe_per_seg = 650\n",
    "mat = torch.from_numpy(np.load('mat.npy')[(-nseg*nframe_per_seg):]).to(device)\n",
    "denoised_mat = torch.from_numpy(np.load('denoised_mat.npy')[(-nseg*nframe_per_seg):]).to(device)\n",
    "nframe, nrow, ncol = mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.from_numpy(np.load('trefide_demo.npy')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_map = get_cor_map_4d(mat.reshape(nseg, -1, nrow, ncol))\n",
    "# label_image, regions = get_label_image(cor_map)\n",
    "# label_image = torch.from_numpy(label_image).to(device)\n",
    "# imshow(cor_map)\n",
    "# plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)\n",
    "# submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions)\n",
    "# denoised_submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_detrend = False\n",
    "apply_fft = False\n",
    "cor_map, label_image, regions = basic_segmentation(mat, median_detrend=median_detrend, fft=apply_fft, fft_max_freq=200, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=None, median_detrend=median_detrend)\n",
    "denoised_submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=None, \n",
    "                                                   median_detrend=median_detrend)\n",
    "# for i in range(len(traces)):\n",
    "#     fig, ax = plt.subplots(figsize=(20, 10))\n",
    "#     ax.set_title(i+1)\n",
    "#     ax.plot(traces[i].cpu(), 'r-', alpha=0.5, label='raw')\n",
    "#     ax.plot(denoised_traces[i].cpu(), 'g-', alpha=0.5, label='denoised')\n",
    "#     ax.legend()\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_labels = label_image.max().item()\n",
    "# fig, ax = plt.subplots(num_labels, figsize=(20, 10*num_labels))\n",
    "# for i in range(len(traces)):\n",
    "#     ax[i].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[i].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[i].legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# start_time = time.time()\n",
    "# soft_mask, model = semi_supervised_segmentation(mat, cor_map=cor_map, model=None, out_channels=[8,8,8,8], \n",
    "#                                                 kernel_size=3, frames_per_iter=100, num_iters=100, \n",
    "#                                                 print_every=20, select_frames=False, optimizer_fn=torch.optim.AdamW, \n",
    "#                                                 optimizer_fn_args = {'lr': 1e-2, 'weight_decay': 1e-3}, \n",
    "#                                                 save_loss_folder=None, loss_threshold=0, reduction='mean',\n",
    "#                                                 last_out_channels=None,\n",
    "#                                                 return_model=True, verbose=True)\n",
    "# print(time.time() - start_time)\n",
    "\n",
    "# imshow(soft_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft_max_freq = 200\n",
    "# tmp = denoised_traces[:2]\n",
    "# tmp = tmp - get_local_median(tmp, dim=-1)\n",
    "# tmp = torch.rfft(tmp, signal_ndim=1, normalized=True)[..., :fft_max_freq, :].reshape(tmp.size(0), -1)\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.plot(tmp.T.cpu())\n",
    "# plt.title(f'Correlation {simple_cosine_similarity(tmp)[0, 1].item()}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regionprops(label_image.cpu().numpy())\n",
    "box_coords = soma_coords.new_tensor(np.array([region.bbox for region in regions]))[:, [1, 3, 0, 2]]\n",
    "box_coords = box_coords.reshape(box_coords.shape[0], box_coords.shape[1]//2, 2)\n",
    "selected = mark_points_in_intervals(soma_coords, box_coords)\n",
    "false_negatives = [i+1 for i in torch.nonzero(selected.sum(1) == 0, as_tuple=True)[0].tolist()]\n",
    "false_positives = [i+1 for i in torch.nonzero(selected.sum(0) == 0, as_tuple=True)[0].tolist()]\n",
    "boxes_with_multiple_pts = [i+1 for i in torch.nonzero(selected.sum(0) > 1, as_tuple=True)[0].tolist()]\n",
    "print('False Negatives (missed {} neurons): {}'.format(len(false_negatives), false_negatives))\n",
    "print('False Positives ({} empty boxes): {}'.format(len(false_positives), false_positives))\n",
    "print('{} boxes_with_multiple_pts: {}'.format(len(boxes_with_multiple_pts), \n",
    "                   {i: (torch.nonzero(selected[:, i-1], as_tuple=True)[0]+1).tolist() for i in boxes_with_multiple_pts}))\n",
    "good_box_idx = torch.nonzero(selected.sum(0)==1, as_tuple=True)[0]\n",
    "soma_idx = torch.nonzero(selected[:, good_box_idx].T, as_tuple=True)[1]\n",
    "print('{} good boxes: {}'.format(len(good_box_idx), [(i+1, j+1) for i, j in zip(good_box_idx.tolist(), soma_idx.tolist())]))\n",
    "\n",
    "figsize = (20, 10)\n",
    "sel_idx = None\n",
    "image_label_overlay = label2rgb(label_image.cpu().numpy(), image=cor_map.cpu().numpy())\n",
    "regions = regionprops(label_image.cpu().numpy())\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.imshow(image_label_overlay)\n",
    "for i, region in enumerate(regions):\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red' if sel_idx is not None and i==sel_idx else 'green', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(minc, minr-1, i+1, color='g', fontweight='bold')\n",
    "for i, (x, y) in enumerate(soma_coords):\n",
    "    ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "    ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# num_labels = label_image.max().item()\n",
    "# fig, ax = plt.subplots(num_labels, figsize=(20, 10*num_labels))\n",
    "# for i in range(len(traces)):\n",
    "#     ax[i].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[i].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[i].legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# num_labels = len(good_box_idx)\n",
    "# fig, ax = plt.subplots(num_labels, 2, figsize=(20, 10*num_labels))\n",
    "# for k, (i, j) in enumerate(zip(good_box_idx.tolist(), soma_idx.tolist())):\n",
    "#     ax[k, 0].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[k, 0].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[k, 0].legend()\n",
    "#     ax[k, 0].set_title(f'Box {i+1}')\n",
    "#     ax[k, 1].plot(true_traces[j].cpu(), 'g-', label='true')\n",
    "#     ax[k, 1].legend()\n",
    "#     ax[k, 1].set_title(f'Neuron {j+1}')\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_label_idx = 7\n",
    "split_clusters(sel_label_idx, denoised_mat, label_image, cor_threshold=0.9, soft_threshold=True, min_num_pixels=50, max_dist=2,\n",
    "              median_detrend=True, apply_fft=True, fft_max_freq=200, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "soft_threshold = True\n",
    "cor_threshold = None\n",
    "verbose = True\n",
    "sel_label_idx = 1\n",
    "while sel_label_idx <= label_image.max():\n",
    "    if verbose:\n",
    "        print(sel_label_idx)\n",
    "    split_clusters(sel_label_idx, mat, label_image, cor_threshold=cor_threshold, soft_threshold=soft_threshold, \n",
    "                   min_num_pixels=50, max_dist=2, median_detrend=True, apply_fft=True, fft_max_freq=200, verbose=verbose)\n",
    "    sel_label_idx += 1\n",
    "print(f'Time spent: {time.time() - start_time:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "soft_threshold = False\n",
    "cor_threshold = 0.95\n",
    "verbose = True\n",
    "sel_label_idx = 1\n",
    "while sel_label_idx <= label_image.max():\n",
    "    if verbose:\n",
    "        print(sel_label_idx)\n",
    "    split_clusters(sel_label_idx, denoised_mat, label_image, cor_threshold=cor_threshold, soft_threshold=soft_threshold, \n",
    "                   min_num_pixels=50, max_dist=2, median_detrend=True, apply_fft=True, fft_max_freq=200, verbose=verbose)\n",
    "    sel_label_idx += 1\n",
    "print(f'Time spent: {time.time() - start_time:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regionprops(label_image.cpu().numpy())\n",
    "box_coords = soma_coords.new_tensor(np.array([region.bbox for region in regions]))[:, [1, 3, 0, 2]]\n",
    "box_coords = box_coords.reshape(box_coords.shape[0], box_coords.shape[1]//2, 2)\n",
    "selected = mark_points_in_intervals(soma_coords, box_coords)\n",
    "false_negatives = [i+1 for i in torch.nonzero(selected.sum(1) == 0, as_tuple=True)[0].tolist()]\n",
    "false_positives = [i+1 for i in torch.nonzero(selected.sum(0) == 0, as_tuple=True)[0].tolist()]\n",
    "boxes_with_multiple_pts = [i+1 for i in torch.nonzero(selected.sum(0) > 1, as_tuple=True)[0].tolist()]\n",
    "print('False Negatives (missed {} neurons): {}'.format(len(false_negatives), false_negatives))\n",
    "print('False Positives ({} empty boxes): {}'.format(len(false_positives), false_positives))\n",
    "print('{} boxes_with_multiple_pts: {}'.format(len(boxes_with_multiple_pts), \n",
    "                   {i: (torch.nonzero(selected[:, i-1], as_tuple=True)[0]+1).tolist() for i in boxes_with_multiple_pts}))\n",
    "good_box_idx = torch.nonzero(selected.sum(0)==1, as_tuple=True)[0]\n",
    "soma_idx = torch.nonzero(selected[:, good_box_idx].T, as_tuple=True)[1]\n",
    "print('{} good boxes: {}'.format(len(good_box_idx), [(i+1, j+1) for i, j in zip(good_box_idx.tolist(), soma_idx.tolist())]))\n",
    "print(torch.unique(soma_idx).numel())\n",
    "\n",
    "figsize = (20, 10)\n",
    "sel_idx = None\n",
    "image_label_overlay = label2rgb(label_image.cpu().numpy(), image=cor_map.cpu().numpy())\n",
    "regions = regionprops(label_image.cpu().numpy())\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.imshow(image_label_overlay)\n",
    "for i, region in enumerate(regions):\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red' if sel_idx is not None and i==sel_idx else 'green', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(minc, minr-1, i+1, color='g', fontweight='bold')\n",
    "for i, (x, y) in enumerate(soma_coords):\n",
    "    ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "    ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# num_labels = label_image.max().item()\n",
    "# fig, ax = plt.subplots(num_labels, figsize=(20, 10*num_labels))\n",
    "# for i in range(len(traces)):\n",
    "#     ax[i].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[i].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[i].legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_image_initial = label((label_image > 0).float().cpu())\n",
    "regions_initial = regionprops(label_image_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image_initial, regions_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_idx = 2\n",
    "i = box_idx - 1\n",
    "minr, minc, maxr, maxc = regions_initial[i].bbox\n",
    "# submat = denoised_mat[:, minr:maxr, minc:maxc]\n",
    "submat = mat[:, minr:maxr, minc:maxc]\n",
    "sub_label_image = label_image[minr:maxr, minc:maxc].clone()\n",
    "imshow(label_image_initial[minr:maxr, minc:maxc])\n",
    "imshow(sub_label_image)\n",
    "sub_label_image[label_image_initial[minr:maxr, minc:maxc]!=box_idx] = 0\n",
    "sub_regions = regionprops(sub_label_image.cpu().numpy())\n",
    "imshow(submat.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "assignment = torch.zeros(len(sub_regions), (sub_label_image>0).sum().item(), device=submat.device)\n",
    "for i, region in enumerate(sub_regions):\n",
    "    row_idx, col_idx = torch.nonzero(sub_label_image==region.label, as_tuple=True)\n",
    "    m = submat[:, row_idx, col_idx]\n",
    "    trace = m.mean(1)\n",
    "    assignment[i, sub_label_image[sub_label_image>0] == region.label] = torch.matmul(trace, m)/(trace**2).sum()\n",
    "    traces.append(m.mean(1))\n",
    "traces = torch.stack(traces, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_multiple_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_traces(traces, colors=good_colors, multiple_figures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(assignment!=0).sum(1).tolist() == [region.area for region in sub_regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = torch.nonzero(sub_label_image>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(sub_label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = assignment.clone()\n",
    "x.requires_grad = True\n",
    "y = traces.T.clone()\n",
    "y.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "loss_history = []\n",
    "optimizer = torch.optim.AdamW([x, y], lr=1e-3, weight_decay=1e-4)\n",
    "num_iters = 10\n",
    "print_every = num_iters//10\n",
    "for i in range(num_iters):\n",
    "    loss_mse = loss_fn(torch.mm(y, x), m)\n",
    "    \n",
    "    ds = []\n",
    "    for i in range(len(x)):\n",
    "        d = manhattan_distance(coords[x[i]!=0])\n",
    "        d[range(len(d)), range(len(d))]  = d.max()\n",
    "        ds.append(d.min(dim=1)[0].max())\n",
    "    loss_connected = sum(ds)\n",
    "    loss_sparsity = -(x==0).float().mean()\n",
    "    \n",
    "    loss = loss_mse + loss_connected + loss_sparsity \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append([loss_mse.item(), loss_connected.item(), loss_sparsity.item()])\n",
    "    if i==0 or (i+1)%print_every==0 or i==num_iters-1:\n",
    "        print(i+1, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x!=0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx, col_idx = torch.nonzero(sub_label_image>0, as_tuple=True)\n",
    "m = submat[:, row_idx, col_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.matmul(traces[0], m)/(traces**2).sum(dim=1, keepdim=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, region in enumerate(sub_regions):\n",
    "    plt.plot(traces[i].cpu(), label=region.label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mat = denoised_mat.mean(0)\n",
    "denoised_mat -= mean_mat\n",
    "plt.plot(denoised_mat.mean((1,2)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1 - 1\n",
    "submat = denoised_submats[i]\n",
    "minr, minc, maxr, maxc = regions[i].bbox\n",
    "row_idx, col_idx = torch.nonzero(label_image[minr:maxr, minc:maxc] == 0, as_tuple=True)\n",
    "plt.plot(submat[:, row_idx, col_idx].mean(1).cpu(), label='background 5')\n",
    "i = 25\n",
    "submat = denoised_submats[i]\n",
    "minr, minc, maxr, maxc = regions[i].bbox\n",
    "row_idx, col_idx = torch.nonzero(label_image[minr:maxr, minc:maxc] == 0, as_tuple=True)\n",
    "plt.plot(submat[:, row_idx, col_idx].mean(1).cpu(), label='background 25')\n",
    "plt.plot(traces[4].cpu(), label='5')\n",
    "plt.plot(traces[24].cpu(), label='25')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submat = submats[4]\n",
    "imshow(submat.mean(0))\n",
    "imshow(((label_image==5)|(label_image==25)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=None, median_detrend=median_detrend)\n",
    "denoised_submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=None, \n",
    "                                                   median_detrend=median_detrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image=label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 5, 26\n",
    "i -= 1\n",
    "j -= 1\n",
    "plt.plot(submats[i].mean((1,2)).cpu()[300:400])\n",
    "plt.plot(submats[j].mean((1,2)).cpu()[300:400])\n",
    "plt.show()\n",
    "plt.plot(true_traces[14].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(good_box_idx)\n",
    "fig, ax = plt.subplots(num_labels, 2, figsize=(20, 10*num_labels))\n",
    "for k, (i, j) in enumerate(zip(good_box_idx.tolist(), soma_idx.tolist())):\n",
    "    ax[k, 0].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "    ax[k, 0].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "    ax[k, 0].legend()\n",
    "    ax[k, 0].set_title(f'Box {i+1}')\n",
    "    ax[k, 1].plot(true_traces[j].cpu(), 'g-', label='true')\n",
    "    ax[k, 1].legend()\n",
    "    ax[k, 1].set_title(f'Neuron {j+1}')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image=label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel_label_idx in range(1, label_image.max()+1):\n",
    "    # minr, minc, maxr, maxc = regions[sel_label_idx-1].bbox\n",
    "    # submat = mat[:, minr:maxr, minc:maxc]\n",
    "    coords = torch.from_numpy(np.stack(np.nonzero(label_image == sel_label_idx), axis=1)).to(device)\n",
    "    m = denoised_mat[:, coords[:, 0], coords[:, 1]]\n",
    "\n",
    "    dist = manhattan_distance(coords)\n",
    "    dist.fill_diagonal_(999)\n",
    "    adj_mat = (dist <= 2)\n",
    "\n",
    "    fft = torch.rfft(m.T, signal_ndim=1, normalized=True).reshape(m.size(1), -1)\n",
    "    fft = fft - fft.mean(1, keepdim=True)\n",
    "    norm = torch.norm(fft, dim=1)\n",
    "    cor = torch.mm(fft, fft.T) / (norm.unsqueeze(1) * norm)\n",
    "    cor[~adj_mat] = 0\n",
    "\n",
    "    laplacian = graph_laplacian(cor)\n",
    "    eigenvalues, eigenvectors = torch.symeig(laplacian, eigenvectors=True)\n",
    "    # fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    # ax.set_title(sel_label_idx)\n",
    "    # ax.plot(eigenvalues.tolist()[:50], 'o-')\n",
    "    # ax.axvline(x=len(torch.nonzero(selected[:, sel_label_idx-1], as_tuple=True)[0]))\n",
    "    # plt.show()\n",
    "\n",
    "    k = 2\n",
    "    labels, dist = k_means(eigenvectors[:,:k], k)\n",
    "    image = torch.zeros_like(cor_map)\n",
    "    image[coords[:, 0], coords[:, 1]] = image.new_tensor(labels+1)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image.cpu().numpy())\n",
    "    ax.set_title(f'{k} {dist.item()}')\n",
    "    for i, (x, y) in enumerate(soma_coords):\n",
    "        ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "        ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    neuron_idx = torch.nonzero(selected[:, sel_label_idx-1], as_tuple=True)[0]\n",
    "    x = torch.stack([m[:, labels==i].mean(1) for i in range(2)], dim=0)\n",
    "    y = true_traces[neuron_idx]\n",
    "    print(simple_cosine_similarity(x[:1], x[1:]).item())\n",
    "    print(simple_cosine_similarity(x, y).tolist())\n",
    "    fig, ax = plt.subplots(2, figsize=(20, 20))\n",
    "    for i in range(2):\n",
    "        ax[0].plot(x[i].cpu(), label=i+1)\n",
    "    for i, j in enumerate(neuron_idx):\n",
    "        ax[1].plot(y[i].cpu(), label=j.item()+1)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 30, 3)\n",
    "ds = []\n",
    "for k in ks:\n",
    "    labels, dist = k_means(eigenvectors[:,:k], k)\n",
    "    image = torch.zeros_like(cor_map)\n",
    "    image[coords[:, 0], coords[:, 1]] = image.new_tensor(labels+1)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image.cpu().numpy())\n",
    "    ax.set_title(f'{k} {dist.item()}')\n",
    "    for i, (x, y) in enumerate(soma_coords):\n",
    "        ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "        ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    ds.append(dist.item())\n",
    "\n",
    "plt.plot(ks, ds, 'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import simple_linear_regression\n",
    "for i, j in zip(good_box_idx, soma_idx):\n",
    "    i = i.item()\n",
    "    j = j.item()\n",
    "    print(f'Box {i+1}, Soma {j+1}')\n",
    "    print('cor(raw, denoised) = {:.2f}'.format(nn.functional.cosine_similarity(traces[i], traces_denoised[i], dim=0).item()))\n",
    "    print('cor(raw, true) = {:.2f}'.format(nn.functional.cosine_similarity(traces[i], true_traces[j], dim=0)))\n",
    "    print('cor(denoised, true) = {:.2f}'.format(nn.functional.cosine_similarity(traces_denoised[i], true_traces[j], dim=0)))\n",
    "    fig, ax = plt.subplots(3)\n",
    "    ax[0].plot(traces[i].cpu(), label='raw', alpha=0.5, c='b')\n",
    "    ax[0].plot(traces_denoised[i].cpu(), label='denoised', c='r')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(true_traces[j].cpu(), c='g', label='true')\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(simple_linear_regression(traces[i], true_traces[j], return_fitted=True).cpu(), label='raw', alpha=0.5, c='b')\n",
    "    ax[2].plot(simple_linear_regression(traces_denoised[i], true_traces[j], return_fitted=True).cpu(), label='denoised', alpha=0.5, c='r')\n",
    "    ax[2].plot(true_traces[j].cpu(), c='g', alpha=0.5, label='true')\n",
    "    ax[2].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = adaptive_avg_pool(mat, (256, nrow, ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rfft(m.transpose(0, 2), signal_ndim=1, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = get_cor_map(m.transpose(1, 2).transpose(0, 3).reshape(-1, 180, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(cor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(adaptive_avg_pool(m, label_image.shape))\n",
    "imshow(label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_label = 8\n",
    "idx1, idx2 = np.nonzero(label_image==sel_label)\n",
    "order = cor_map[idx1, idx2].sort()[1].tolist()\n",
    "idx1, idx2 = idx1[order], idx2[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = denoised_mat[:, idx1, idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.rfft((m - m.mean(0)).T, 1, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[:, 250:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.irfft(f, 1, normalized=True, signal_sizes=[1000]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m2[:, 0].cpu())\n",
    "plt.show()\n",
    "plt.plot(m[:, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f[0, :, 0].cpu())\n",
    "plt.show()\n",
    "plt.plot(f[0, :, 1].cpu())\n",
    "plt.show()\n",
    "plt.plot(m[:, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_somas = selected.sum(0)\n",
    "for i in range(1, label_image.max()+1):\n",
    "    idx1, idx2 = np.nonzero(label_image==i)\n",
    "    m = mat[:, idx1, idx2]\n",
    "    with torch.no_grad():\n",
    "        u, s, v = torch.svd(m)\n",
    "    plt.plot(s[1:].cpu(), 'o-')\n",
    "    plt.title('{}: {}: {}'.format(i+1, num_somas[i-1].item(), s[:5].tolist()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_somas = selected.sum(0)\n",
    "for i, submat in enumerate(submats):\n",
    "    m = adaptive_avg_pool(submat, (256, 16, 16)).reshape(256, 256)\n",
    "    with torch.no_grad():\n",
    "        eigenvalues, eigenvectors = torch.eig(m)\n",
    "        eigenvalues = torch.norm(eigenvalues, dim=1)\n",
    "    plt.plot(eigenvalues.cpu()[1:], 'o-')\n",
    "    plt.title('{}: {}: {}'.format(i+1, num_somas[i].item(), eigenvalues[:5].tolist()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "submats[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_maps = [get_cor_map(m) for m in [mat, denoised_mat, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = target\n",
    "noisy = m + torch.randn_like(m) * m.std()*0.1\n",
    "cor = get_cor_map(noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(masks.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder = f'{data_folder}/individual_neurons'\n",
    "if not os.path.exists(fig_folder):\n",
    "    print(f'Create {fig_folder}')\n",
    "    os.makedirs(fig_folder)\n",
    "if not os.path.exists(f'{fig_folder}/individual_neurons.gif'):\n",
    "    for i in range(len(masks)):\n",
    "        y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        im = ax.imshow(cor_map.cpu().numpy(), cmap='gray')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        fig.colorbar(im, cax=cax)\n",
    "        ax.scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.5)\n",
    "        ax.scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "        ax.set_title(f'Neuron {i} (soma is red)')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f'{fig_folder}/{i}.png')\n",
    "        plt.close()\n",
    "    save_gif_file(imgs=[f'{fig_folder}/{i}.png' for i in range(len(masks))], save_path=f'{fig_folder}/individual_neurons.gif')\n",
    "\n",
    "    img = masks.sum(0).cpu()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    im = ax.imshow(img, cmap=matplotlib.cm.get_cmap('viridis', img.max()+1))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    ax.scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r', s=20, alpha=0.5)\n",
    "    ax.set_title('Overlapping of neurons (red dots are somas)')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{fig_folder}/overlapping.png')\n",
    "    plt.show()\n",
    "    \n",
    "if not os.path.exists(f'{fig_folder}/individual_neurons_with_spikes.gif'):\n",
    "    for i in range(len(masks)):\n",
    "        y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "        fig, ax = plt.subplots(2, figsize=(16, 16))\n",
    "        im = ax[0].imshow(cor_map.cpu().numpy(), cmap='gray')\n",
    "        divider = make_axes_locatable(ax[0])\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        fig.colorbar(im, cax=cax)\n",
    "        ax[0].scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.5)\n",
    "        ax[0].scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "        ax[0].set_title(f'Neuron {i} (soma is red)')\n",
    "        ax[1].plot(traces[i].cpu())\n",
    "        ax[1].set_title(f'Neuron {i} mean fluorescence trace')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f'{fig_folder}/{i}.png')\n",
    "        plt.close()\n",
    "    save_gif_file(imgs=[f'{fig_folder}/{i}.png' for i in range(len(masks))], save_path=f'{fig_folder}/individual_neurons_with_spikes.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = get_cor_map(mat, topk=5)\n",
    "label_image, regions = get_label_image(cor_map, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()\n",
    "soft_mask, model = semi_supervised_segmentation(mat, cor_map=cor_map, model=None, out_channels=[8,8,8,8], \n",
    "                                                kernel_size=3, frames_per_iter=100, num_iters=100, \n",
    "                                                print_every=20, select_frames=False, optimizer_fn=torch.optim.AdamW, \n",
    "                                                optimizer_fn_args = {'lr': 1e-2, 'weight_decay': 1e-3}, \n",
    "                                                save_loss_folder=None, loss_threshold=0, reduction='mean',\n",
    "                                                last_out_channels=None,\n",
    "                                                return_model=True, verbose=True)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(cor_map)\n",
    "imshow(soft_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "frames_per_iter = 100\n",
    "num_iters = 10\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    soft_masks = []\n",
    "    starts = []\n",
    "    for i in range(num_iters):\n",
    "        start = np.random.choice(901)\n",
    "        starts.append(start)\n",
    "        x = mat[start:start+frames_per_iter]\n",
    "        y_pred = model(x).mean(1)\n",
    "        soft_mask = torch.softmax(y_pred, dim=0)[1]\n",
    "        soft_masks.append(soft_mask)\n",
    "end_time = time.time()\n",
    "print(f'Time spent: {end_time - start_time}')\n",
    "soft_mask = torch.stack(soft_masks, dim=0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(starts):\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].plot(mat[s:s+frames_per_iter].mean((1,2)).cpu())\n",
    "    ax[0].set_title(f'{s}-{s+frames_per_iter}')\n",
    "    im = ax[1].imshow(soft_masks[i].cpu().numpy())\n",
    "    divider = make_axes_locatable(ax[1])\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(soft_mask.cpu(), cmap='Reds', alpha=0.5)\n",
    "plt.imshow(cor_map.cpu(), cmap='Blues', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_mask = torch.stack(soft_masks, dim=0).mean(0)\n",
    "imshow(soft_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(masks)):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    im = ax.imshow(soft_mask.cpu().numpy(), cmap='gray', alpha=1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "    ax.scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.2)\n",
    "    ax.scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "    ax.set_title(f'Neuron {i} (soma is red)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "im = ax.imshow(soft_mask.cpu().numpy(), cmap='gray', alpha=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "for i in range(len(masks)):\n",
    "    y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "    ax.scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.2)\n",
    "for i in range(len(masks)):\n",
    "    ax.scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "ax.set_title(f'Neuron masks (soma is red)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "import matplotlib.patches as mpatches\n",
    "bounding_box = True\n",
    "img = label2rgb(label_image, image=cor_map.cpu())\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "im = ax.imshow(img)\n",
    "if bounding_box:\n",
    "    for i, region in enumerate(regions):\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='green', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(minc, minr, i+1, color='r')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax.scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r', s=20, alpha=0.5)\n",
    "for i, (x, y) in enumerate(soma_coords):\n",
    "    ax.text(x, y, i, color='b')\n",
    "ax.set_title('Basic pipeline segmentation')\n",
    "ax.set_axis_off()\n",
    "fig.tight_layout()\n",
    "# if not os.path.exists(f'{fig_folder}/segmentation_basic.png'):\n",
    "#     plt.savefig(f'{fig_folder}/segmentation_basic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 1\n",
    "num_components = 4\n",
    "minr, minc, maxr, maxc = regions[label_idx-1].bbox\n",
    "selected_frame_slice = slice(100, 700)\n",
    "selected_row_slice = slice(minr, maxr)\n",
    "selected_col_slice = slice(minc, maxc)\n",
    "selected_indices = (selected_frame_slice, selected_row_slice, selected_col_slice)\n",
    "\n",
    "submat = denoised_mat[selected_indices]\n",
    "mask = None\n",
    "# sub_cor_map = get_cor_map(submat)\n",
    "# sub_label_image, sub_regions = get_label_image(sub_cor_map, plot=True)\n",
    "\n",
    "\n",
    "# submat = denoised_mat[selected_frame_slice, label_image==label_idx]\n",
    "# mask = (label_image == label_idx)[selected_row_slice, selected_col_slice]\n",
    "\n",
    "W, H = plain_nmf(submat, n=num_components, mask=mask, fig_folder=None, save_npy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 31\n",
    "# plt.plot(target[selected_frame_slice, soma_coords[neuron_idx, 1], soma_coords[neuron_idx, 0]].cpu())\n",
    "plt.plot(traces[neuron_idx, selected_frame_slice].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '2d-noise2self_with_features'\n",
    "filepath = f'{save_folder}/denoised_movie_full_step64000.npy'\n",
    "pred = torch.from_numpy(np.load(filepath)).float().to(device)\n",
    "select_idx = range(100, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_name = 'median-5'\n",
    "pred_filtered = get_local_median(pred, window_size=15, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f'{save_folder}/mb-spike/spike.npy'\n",
    "spike_name = 'mb-spike'\n",
    "pred_filtered = torch.from_numpy(np.load(filepath)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_video_ffmpeg(torch.cat([scale_and_shift(m, scale=255) \n",
    "                             for m in [target[select_idx], pred[select_idx], pred_filtered[[select_idx]]]], dim=1), \n",
    "                  f'{spike_name}.avi', \n",
    "                  normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pred_filtered[select_idx].reshape(600, -1).cpu().numpy()\n",
    "min_val = M.min()\n",
    "M = M - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "ns = [51]\n",
    "fig_folder = f'{save_folder}/nmf_spike/{spike_name}'\n",
    "if not os.path.exists(fig_folder):\n",
    "    print(f'Creat folder {fig_folder}')\n",
    "    os.makedirs(fig_folder)\n",
    "for n in ns:\n",
    "    start_time = time.time()\n",
    "    model = NMF(n_components=n, init='random', random_state=0)\n",
    "    W = model.fit_transform(M)\n",
    "    H = model.components_\n",
    "    end_time = time.time()\n",
    "    print(n, end_time - start_time)\n",
    "    np.save(f'{fig_folder}/w_{n}.npy', W)\n",
    "    np.save(f'{fig_folder}/h_{n}.npy', H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(H.shape[0]):\n",
    "    fig, ax = plt.subplots(2, figsize=(20, 15))\n",
    "    ax[0].set_title(f'Component {i+1}')\n",
    "    im = ax[0].imshow(H[i].reshape(180, 512))\n",
    "    divider = make_axes_locatable(ax[0])\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    ax[1].plot(W[:, i])\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{fig_folder}/{i}.png')\n",
    "    plt.close()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "# Create the frames\n",
    "frames = []\n",
    "imgs = [f'{fig_folder}/{n}.png' for n in range(H.shape[0])]\n",
    "for i in imgs:\n",
    "    new_frame = Image.open(i)\n",
    "    frames.append(new_frame)\n",
    "frames[0].save(f'{fig_folder}/nmf.gif', format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=1500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = get_cor_map(mat, topk=4)\n",
    "target = clean - trend\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(16, 21))\n",
    "im = ax[0].imshow(cor_map.cpu().numpy())\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[0].scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r')\n",
    "ax[0].set_title('correlation map of noisy video (red dots are somas)')\n",
    "im = ax[1].imshow(target.mean(0).cpu().numpy())\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[1].scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r')\n",
    "ax[1].set_title('temporal mean of the clean video (red dots are somas)')\n",
    "im = ax[2].imshow(clean.mean(0).cpu().numpy())\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[2].scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r')\n",
    "ax[2].set_title('temporal mean of the clean video (before detrending)')\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{data_folder}/cor_map.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(10, 5, figsize=(20, 30))\n",
    "for i in range(50):\n",
    "    x, y = i//5, i%5\n",
    "    ax[x, y].imshow((cor_map*masks[i].float()).cpu().numpy())\n",
    "    ax[x, y].set_title(f'{i}')\n",
    "    ax[x, y].scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r')\n",
    "fig.tight_layout()\n",
    "plt.title('Individual neurons on correlation map')\n",
    "plt.savefig(f'{data_folder}/individual_neurons_cor_map.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 30))\n",
    "plt.plot(traces.T.cpu())\n",
    "plt.title('Neuron mean fluorescence')\n",
    "plt.savefig(f'{data_folder}/individual_neurons_mean_fluorescence.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_traces = torch.stack([mat[:, mask].mean(dim=1) for mask in masks], dim=1).T.cpu().numpy()\n",
    "clean_traces = torch.stack([target[:, mask].mean(dim=1) for mask in masks], dim=1).T.cpu().numpy()\n",
    "step = np.max(clean_traces.max(1) - clean_traces.min(1))\n",
    "fig, ax = plt.subplots(figsize=(10, 80))\n",
    "for i in range(len(raw_traces)):\n",
    "    ax.plot(raw_traces[i] - i*step, 'g-.', markersize=1, alpha=0.8, label='noisy' if i==0 else None)\n",
    "    ax.plot(clean_traces[i] - i*step, 'r-', markersize=1, alpha=0.5, label='clean' if i==0 else None)\n",
    "    ax.text(-30, -i*step, f'{i+1}')\n",
    "ax.set_ylim(-step*len(raw_traces), step)\n",
    "ax.legend()\n",
    "ax.set_title('Mean traces (noisy and clean)')\n",
    "plt.savefig(f'{data_folder}/mean_traces.png')\n",
    "plt.show()\n",
    "\n",
    "raw_traces = mat[:, mask_soma].T.cpu().numpy()\n",
    "clean_traces = target[:, mask_soma].T.cpu().numpy()\n",
    "step = np.max(clean_traces.max(1) - clean_traces.min(1))\n",
    "fig, ax = plt.subplots(figsize=(10, 80))\n",
    "for i in range(len(raw_traces)):\n",
    "    ax.plot(raw_traces[i] - i*step, 'g-.', markersize=1, alpha=0.8, label='noisy' if i==0 else None)\n",
    "    ax.plot(clean_traces[i] - i*step, 'r-', markersize=1, alpha=0.5, label='clean' if i==0 else None)\n",
    "    ax.text(-30, -i*step, f'{i+1}')\n",
    "ax.set_ylim(-step*len(raw_traces), step)\n",
    "ax.legend()\n",
    "ax.set_title('Soma traces (noisy and clean)')\n",
    "plt.savefig(f'{data_folder}/soma_traces.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'cp', f'{data_folder}/*png', f'gs://tma-opp-test/optosynth/optosynth_test_mb/data/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'cellmincer-with_global_features_mse'\n",
    "if not os.path.exists(save_folder):\n",
    "    print(f'Download folder gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}')\n",
    "    command = ['gsutil', '-m', 'cp', '-r', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}', '.']\n",
    "    response = subprocess.run(command, capture_output=True)\n",
    "    assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_folder)\n",
    "movie_start_idx = 100\n",
    "movie_end_idx = 700\n",
    "if re.search('cellmincer', save_folder):\n",
    "    num_epochs = 80\n",
    "    if re.search('epochs', save_folder):\n",
    "        num_epochs = int(save_folder[-8:-6])\n",
    "    num_iters = 1000\n",
    "else:\n",
    "    with open(f'{save_folder}/config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    num_episodes = len([k for k in config.keys() if re.search('^episode', k)])\n",
    "    num_epochs = sum([config[f'episode{e}']['train_settings']['num_epochs'] for e in range(num_episodes)])\n",
    "    num_iters = config['episode0']['train_settings']['num_iters']\n",
    "print(num_iters, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (clean-trend)[movie_start_idx:movie_end_idx]\n",
    "if not os.path.exists(f'{data_folder}/movie_frame{movie_start_idx}to{movie_end_idx}_clean.avi'):\n",
    "    print(f'Make video {data_folder}/movie_frame{movie_start_idx}to{movie_end_idx}_clean.avi')\n",
    "    make_video_ffmpeg(target, save_path=f'{data_folder}/movie_frame{movie_start_idx}to{movie_end_idx}_clean.avi')\n",
    "losses = []\n",
    "losses_train = []\n",
    "for epoch in range(num_epochs):\n",
    "    pred = target.new_tensor(\n",
    "        np.load(f'{save_folder}/denoised_movie_frame{movie_start_idx}to{movie_end_idx}_step{num_iters * (epoch+1)}.npy', allow_pickle=True))\n",
    "    losses.append([get_loss(pred, target, mask=None),\n",
    "                   get_loss(pred, target, mask=mask_cell),\n",
    "                   get_loss(pred, target, mask=mask_soma),\n",
    "                   get_loss(pred, target, mask=~mask_cell)])\n",
    "    losses_train.append([get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=None),\n",
    "                   get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=mask_cell),\n",
    "                   get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=mask_soma),\n",
    "                   get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=~mask_cell)])\n",
    "    print(epoch, losses[-1])\n",
    "    print(epoch, losses_train[-1])\n",
    "save_path = f'{save_folder}/diff_movie_frame{movie_start_idx}to{movie_end_idx}_step{num_iters * (epoch+1)}.avi'\n",
    "make_video_ffmpeg(pred - target, \n",
    "                  save_path=save_path)\n",
    "command = ['gsutil', 'cp', save_path, f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0\n",
    "losses = np.array(losses)\n",
    "pandas.DataFrame(losses, columns=['all', 'cell', 'soma', 'background']).to_pickle(f'{save_folder}/rmse_losses.pkl')\n",
    "losses_train = np.array(losses_train)\n",
    "pandas.DataFrame(losses_train, columns=['all', 'cell', 'soma', 'background']).to_pickle(f'{save_folder}/rmse_losses_train.pkl')\n",
    "fig, ax = plt.subplots(5, sharex=True, figsize=(10, 20))\n",
    "ax[0].plot(losses[:, 0], 'ro-', label='all')\n",
    "ax[0].legend()\n",
    "ax[1].plot(losses[:, 1], 'bo-', label='cell')\n",
    "ax[1].legend()\n",
    "ax[2].plot(losses[:, 2], 'go-', label='soma')\n",
    "ax[2].legend()\n",
    "ax[3].plot(losses[:, 3], 'ko-', label='background')\n",
    "ax[3].legend()\n",
    "ax[4].plot(losses[:, 0], 'ro-', label='all')\n",
    "ax[4].plot(losses[:, 1], 'bo-', label='cell')\n",
    "ax[4].plot(losses[:, 2], 'go-', label='soma')\n",
    "ax[4].plot(losses[:, 3], 'ko-', label='background')\n",
    "ax[4].legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{save_folder}/rmse_losses.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(5, sharex=True, figsize=(10, 20))\n",
    "ax[0].plot(losses_train[:, 0], 'ro-', label='all')\n",
    "ax[0].legend()\n",
    "ax[1].plot(losses_train[:, 1], 'bo-', label='cell')\n",
    "ax[1].legend()\n",
    "ax[2].plot(losses_train[:, 2], 'go-', label='soma')\n",
    "ax[2].legend()\n",
    "ax[3].plot(losses_train[:, 3], 'ko-', label='background')\n",
    "ax[3].legend()\n",
    "ax[4].plot(losses_train[:, 0], 'ro-', label='all')\n",
    "ax[4].plot(losses_train[:, 1], 'bo-', label='cell')\n",
    "ax[4].plot(losses_train[:, 2], 'go-', label='soma')\n",
    "ax[4].plot(losses_train[:, 3], 'ko-', label='background')\n",
    "ax[4].legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{save_folder}/rmse_losses_train.png')\n",
    "plt.show()\n",
    "\n",
    "command = ['gsutil', 'cp', f'{save_folder}/rmse*', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 3200\n",
    "# model.load_state_dict(torch.load(f'{save_folder}/model_step{i}.pt'))\n",
    "\n",
    "# mean_mat = mat.mean()\n",
    "# std_mat = mat.std()\n",
    "# denoised_mat = model_denoise(((mat - mean_mat) / std_mat)[movie_start_idx-frame_depth:movie_end_idx+frame_depth], model, ndim=ndim, frame_depth=frame_depth,\n",
    "#                                  normalize=False, batch_size=batch_size_eval, replicate_pad=False)\n",
    "# denoised_mat = denoised_mat * std_mat + mean_mat\n",
    "\n",
    "# np.save(f'{save_folder}/denoised_movie_frame100to700_step{i}.npy', denoised_mat.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '2d-noise2self_with_features'\n",
    "num_iters = 1600\n",
    "num_epochs = 40\n",
    "# save_folder = 'cellmincer-with_global_features'\n",
    "# num_iters = 1000\n",
    "# num_epochs = 80\n",
    "\n",
    "filepath = f'{save_folder}/denoised_movie_frame100to700_step{num_iters*num_epochs}.npy'\n",
    "if not os.path.exists(filepath):\n",
    "    command = ['gsutil', '-m', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{filepath}', filepath]\n",
    "    response = subprocess.run(command, capture_output=True)\n",
    "    assert response.returncode == 0\n",
    "pred = target.new_tensor(np.load(filepath))\n",
    "# cor_map = get_cor_map(pred)\n",
    "# imshow(cor_map, title='correlation map of predicted video', save_file=f'{save_folder}/cor_map_pred_{num_epochs}epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = clean - trend\n",
    "if re.search('cellmincer', save_folder):\n",
    "    pred = target.new_tensor(np.load(f'{save_folder}/denoised_movie_frame0to1000_step{num_iters*num_epochs}.npy'))\n",
    "else:\n",
    "    pred = target.new_tensor(np.load(f'{save_folder}/denoised_movie_full_step{num_iters*num_epochs}.npy'))\n",
    "cor_map = get_cor_map(pred-target, topk=4)\n",
    "fig, ax = plt.subplots(3, figsize=(20, 20))\n",
    "im = ax[0].imshow((pred-target).mean(0).cpu())\n",
    "ax[0].set_title('temporal mean of (pred - target)')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "im = ax[1].imshow((pred-target).abs().mean(0).cpu())\n",
    "ax[1].set_title('temporal mean of |pred - target|')\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "im = ax[2].imshow(cor_map.cpu())\n",
    "ax[2].set_title('correlation map of (pred - target)')\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{save_folder}/temporal_mean_difference_{num_epochs}epochs.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(16, 16))\n",
    "ax[0].set_title('spatial mean')\n",
    "ax[0].plot(pred.mean((1, 2)).cpu(), label='pred')\n",
    "ax[0].plot(target.mean((1,2)).cpu(), label='target')\n",
    "ax[0].legend()\n",
    "ax[1].plot((pred-target).abs().mean((1,2)).cpu(), label='|pred - target|')\n",
    "ax[1].legend()\n",
    "ax[2].plot((pred-target).mean((1,2)).cpu(), label='pred - target')\n",
    "ax[2].legend()\n",
    "plt.savefig(f'{save_folder}/spatial_mean_difference_{num_epochs}epochs.png')\n",
    "plt.show()\n",
    "\n",
    "raw_traces = mat[:, mask_soma].T.cpu().numpy()\n",
    "pred_traces = pred[:, mask_soma].T.cpu().numpy()\n",
    "clean_traces = target[:, mask_soma].T.cpu().numpy()\n",
    "step = np.max(clean_traces.max(1) - clean_traces.min(1))\n",
    "fig, ax = plt.subplots(figsize=(10, 80))\n",
    "for i in range(len(raw_traces)):\n",
    "    ax.plot(raw_traces[i] - i*step, 'b-', markersize=1, alpha=0.3, label='Input' if i==0 else None)\n",
    "    ax.plot(pred_traces[i] - i*step, 'g-', markersize=1, alpha=0.8, label='Prediction' if i==0 else None)\n",
    "    ax.plot(clean_traces[i] - i*step, 'r-', markersize=1, alpha=0.5, label='Target'if i==0 else None)\n",
    "    ax.text(-30, -i*step, f'{i+1}')\n",
    "ax.set_ylim(-step*len(clean_traces), step)\n",
    "ax.legend()\n",
    "ax.set_title('Predicted soma traces')\n",
    "plt.savefig(f'{save_folder}/denoised_soma_traces_{num_epochs}epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'cp', f'{save_folder}/*.png', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'ls', 'gs://tma-opp-test/optosynth/optosynth_test_mb/results/']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0\n",
    "folders = [f.split('/')[-2] for f in response.stdout.decode().split() if re.search('/$', f) and not re.search('figures|diff_movies', f)]\n",
    "movie_start_idx = 100\n",
    "movie_end_idx = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['2d-noise2self_with_features', '2d-noise2self_with_features_80epochs', '2d-noise2self_with_features_80epochs_2',\n",
    "           'cellmincer-with_global_features', 'cellmincer-with_global_features_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        print(folder)\n",
    "        os.makedirs(folder)\n",
    "        command = ['gsutil', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/rmse_losses.pkl', folder]\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "        if not re.search('^cellmincer', folder):\n",
    "            command = ['gsutil', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/config.json', folder]\n",
    "            response = subprocess.run(command, capture_output=True)\n",
    "            assert response.returncode == 0\n",
    "    if re.search('cellmincer', folder):\n",
    "#         num_epochs = 80\n",
    "#         if re.search('epochs', folder):\n",
    "#             num_epochs = int(folder[-8:-6])\n",
    "        num_iters = 1000\n",
    "        command = ['gsutil', 'ls', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/denoised_movie_frame100to700*npy']\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "        num_epochs = max([int(s.split('step')[-1][:-4]) for s in response.stdout.decode().split()]) // num_iters\n",
    "    else:\n",
    "        if not os.path.exists(f'{folder}/config.json'):\n",
    "            command = ['gsutil', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/config.json', folder]\n",
    "            response = subprocess.run(command, capture_output=True)\n",
    "            assert response.returncode == 0\n",
    "        with open(f'{folder}/config.json', 'r') as f:\n",
    "            config = json.load(f)\n",
    "        num_episodes = len([k for k in config.keys() if re.search('^episode', k)])\n",
    "        num_epochs = sum([config[f'episode{e}']['train_settings']['num_epochs'] for e in range(num_episodes)])\n",
    "        num_iters = config['episode0']['train_settings']['num_iters']\n",
    "    print(folder, num_iters, num_epochs)\n",
    "\n",
    "    target = (clean-trend)[movie_start_idx:movie_end_idx]\n",
    "    filepath = f'{folder}/denoised_movie_frame{movie_start_idx}to{movie_end_idx}_step{num_iters*num_epochs}.npy'\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f'Download {filepath}')\n",
    "        command = ['gsutil', '-m', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{filepath}', folder]\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "    pred = target.new_tensor(np.load(filepath))\n",
    "    def normalize(mat, scale=255):\n",
    "        return (mat - mat.min()) / (mat.max() - mat.min()) * scale\n",
    "#     if not os.path.exists(f'diff_movies/{folder}.avi'):\n",
    "#         print(f'Make video diff_movies/{folder}.avi')\n",
    "#         make_video_ffmpeg(torch.cat([normalize(pred), normalize(target), normalize(pred-target)], dim=1), \n",
    "#                           save_path=f'diff_movies/{folder}.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_good_colors()\n",
    "\n",
    "def get_label(model_name):\n",
    "    if model_name.startswith('2d-noise2self') and not model_name.endswith('with_features'):\n",
    "        return '2d-noise2self'\n",
    "    elif model_name.startswith('3d-noise2self'):\n",
    "        return '3d-noise2self'\n",
    "    else:\n",
    "        return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder = 'new-figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['2d-noise2self', '3d-noise2self', 'separate-net', 'cellmincer-with_global_features', 'cellmincer-wo_global_features']\n",
    "# model_names = ['2d-noise2self_2', '3d-noise2self_crop', 'separate-net']\n",
    "# model_names += [folder for folder in folders \n",
    "#                if (re.search('cellmincer', folder)\n",
    "#                    or folder in ['2d-noise2self_with_features'])]\n",
    "# model_names += ['cellmincer-with_global_features', 'cellmincer-wo_global_features']\n",
    "# model_names = [folder for folder in folders \n",
    "#                if (re.search('cellmincer', folder) and not re.search('wo', folder)\n",
    "#                    or folder in ['2d-noise2self_with_features'])]\n",
    "# model_names = ['2d-noise2self_with_features', \n",
    "#                'cellmincer-with_global_features', \n",
    "#                'cellmincer-with_global_features_mse',\n",
    "#               ]\n",
    "\n",
    "model_names = ['2d-noise2self_with_features', '2d-noise2self_with_features_80epochs_2', \n",
    "               'cellmincer-with_global_features', 'cellmincer-with_global_features_80epochs', \n",
    "               'cellmincer-with_global_features_mse',\n",
    "               'cellmincer-with_global_features_mse_80epochs'\n",
    "              ]\n",
    "# model_names = folders\n",
    "roi_names = ['RMSE of all pixels', 'RMSE of masked neuronal pixels', 'RMSE of 50 soma pixels', 'RMSE of background pixels']\n",
    "# colors = ['r', 'g', 'b', 'k', 'c']\n",
    "losses = [pandas.read_pickle(f'{model_name}/rmse_losses.pkl').values for model_name in model_names]\n",
    "fig_folder = 'figures'\n",
    "fig, ax = plt.subplots(len(roi_names), figsize=(20, 20))\n",
    "for j, roi_name in enumerate(roi_names):\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        y = losses[i][range(40) if re.search('2d-noise2self', model_name) else range(80), j]\n",
    "        x = range(1, len(y)+1)\n",
    "        ax[j].plot(x, y, 'o--' if re.search('wo', model_name) else 'o-', color=colors[i], label=model_name.split('_80epochs')[0])\n",
    "        ax[j].set_title(roi_name)\n",
    "        ax[j].set_xlabel('Epoch')\n",
    "        ax[j].set_ylabel('RMSE')\n",
    "        ax[j].legend()\n",
    "fig.tight_layout()\n",
    "# plt.savefig(f'{fig_folder}/five_models.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer-w-wo-features.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer-mse-losses.png')\n",
    "# plt.savefig(f'{fig_folder}/2d-noise2self-with-features.png')\n",
    "# plt.savefig(f'{fig_folder}/2d-noise2self-with-features_all.png')\n",
    "# plt.savefig(f'{fig_folder}/all.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer_2d-noise2self.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer_2d-noise2self_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x: int = 100, y=1):\n",
    "    print(x, y)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'cp', '-r', fig_folder, f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_start_idx = 100\n",
    "movie_end_idx = 700\n",
    "pred = mat[movie_start_idx:movie_end_idx]\n",
    "target = (clean - trend)[movie_start_idx:movie_end_idx]\n",
    "pretrain_loss = [get_loss(pred, target, mask=None), \n",
    " get_loss(pred, target, mask=mask_cell),\n",
    " get_loss(pred, target, mask=mask_soma),\n",
    " get_loss(pred, target, mask=~mask_cell)]\n",
    "\n",
    "roi_names = ['all', 'cell', 'soma', 'background']\n",
    "colors = ['r', 'g', 'b', 'k', 'c']\n",
    "fig, ax = plt.subplots(len(roi_names), figsize=(20, 20))\n",
    "for j, roi_name in enumerate(roi_names):\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        ax[j].plot([pretrain_loss[j]]+losses[i, :, j].tolist(), f'{colors[i]}o-', label=model_name)\n",
    "        ax[j].set_title(roi_name)\n",
    "        ax[j].legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
